{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculus, Cost Function, and Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![best fit line](visuals/best_fit_line.png)\n",
    "\n",
    "The best fit line that goes through the scatterplot up above can be generalized in the following equation: $$y = mx + b$$\n",
    "\n",
    "Of all the possible lines, we can prove why that particular line was chosen using the plot down below:\n",
    "\n",
    "![](visuals/cost_curve.png)\n",
    "\n",
    "where RSS is defined as the residual sum of squares:\n",
    "\n",
    "$$ \n",
    "\\begin{align}\n",
    "RSS &= \\sum_{i=1}^n(actual - expected)^2 \\\\\n",
    "&= \\sum_{i=1}^n(y_i - \\hat{y})^2 \\\\\n",
    "&= \\sum_{i=1}^n(y_i - (mx_i + b))^2\n",
    "\\end{align}\n",
    "$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. What is a more generalized name for the RSS curve above? How is it related to machine learning models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here\n",
    "A more generalized name is cost function. For all models we will attempt to minimize the residual error between the\n",
    "actual values and the model outputs. A useful model minimizes this error, a bad model has a high error. You can find \n",
    "what coefficients produce low errors by finding the coefficent that correponds with the minimum RSS value using the \n",
    "cost function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Would you rather choose a $m$ value of 0.08 or 0.05 from the RSS curve up above?   What is the relation between the position on the cost curve, the error, and the slope of the line?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here\n",
    ".05. .05 is the slope coefficent that produces the minimum RSS value, or, the lowest amount of error. \n",
    "\n",
    "Relation:\n",
    "The position on the cost curve will dictate whether the slope is positive or negative. On this particular cost curve, \n",
    "the error is higher when the slope is steeper, and most of the time the error will me lowest when the slope is 0. \n",
    "The positive/negative componet of the slope tells you which way you need to \"move\" to get closer to where the slope is 0, \n",
    "and therefore helps you find where the error is minimized. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](visuals/gd.png)\n",
    "\n",
    "### 3. Using the gradient descent visual from above, explain why the distance between each step is getting smaller as more steps occur with gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here\n",
    "The step size is getting smaller becasue it is a function of the derivative(or 'steepness') at the point where the step \n",
    "is being calculated. The steeper the derivative, the larger the step is being taken. The flatter the steepness, the small\n",
    "the step. That way you dont over shoot the spot where the error is minimized, and you also reduce the amount of \n",
    "computational power necessary to find a spot where the slope is close to 0. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. What is the purpose of a learning rate in gradient descent? Explain how a very small and a very large learning rate would affect the gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here\n",
    "The purpose of a learning rate is to move along the line/surface of the cost function efficiently, yet effectivley. \n",
    "If your learning rate is too big you will miss the minimum. If it is too small it will be to computationaly intensive\n",
    "to find the minimum. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
